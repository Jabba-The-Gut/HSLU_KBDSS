{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1 N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/jabbathegut/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
     ]
    }
   ],
   "source": [
    "#Testat Aufgabe 1 - N-Grams\n",
    "import nltk, re, string\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords, gutenberg\n",
    "\n",
    "# download gutenberg\n",
    "nltk.download('gutenberg')\n",
    "\n",
    "# load gutenberg corpus\n",
    "text = gutenberg.raw('shakespeare-macbeth.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleanup\n",
    "text = re.sub('<.*>', '', text) # remove xml markup\n",
    "text = re.sub('ENDOFARTICLE.', '', text) # ENDOFARTICLE entfernen\n",
    "text = re.sub(\"[\" + re.sub(\"\\.\",\"\",string.punctuation) + \"]\", \"\", text) # Satzzeichen entfernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text (split in words)\n",
    "tokenized = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenized = [w for w in tokenized if not w in stop_words]\n",
    "\n",
    "# Count bigrams\n",
    "bigrams = ngrams(tokenized, 2)\n",
    "freq_bigrams = nltk.FreqDist(bigrams)\n",
    "freq_dist = nltk.FreqDist(freq_bigrams)\n",
    "for k,v in freq_dist.items():\n",
    "    if v >1 :\n",
    "        print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Enter', 'three', 'Witches') 4\n",
      "('three', 'Witches', '1') 3\n",
      "('Exeunt', 'Scena', 'Secunda') 4\n",
      "('Enter', 'Rosse', 'Angus') 2\n",
      "('worthy', 'Thane', 'Rosse') 2\n",
      "('The', 'Thane', 'Cawdor') 2\n",
      "('Exeunt', 'Scena', 'Tertia') 3\n",
      "('Thunder', 'Enter', 'three') 3\n",
      "('Ile', 'doe', 'Ile') 2\n",
      "('doe', 'Ile', 'doe') 2\n",
      "('And', 'I', 'another') 2\n",
      "('Enter', 'Macbeth', 'Banquo') 2\n",
      "('I', 'haue', 'seene') 4\n",
      "('looke', 'like', 'th') 2\n",
      "('All', 'haile', 'Macbeth') 3\n",
      "('haile', 'Macbeth', 'haile') 2\n",
      "('Macbeth', 'haile', 'thee') 2\n",
      "('haile', 'thee', 'Thane') 2\n",
      "('thee', 'Thane', 'Cawdor') 2\n",
      "('Thane', 'Cawdor', 'liues') 2\n",
      "('Children', 'shall', 'Kings') 2\n",
      "('Exeunt', 'Scena', 'Quarta') 3\n",
      "('But', 'I', 'haue') 3\n",
      "('The', 'Prince', 'Cumberland') 2\n",
      "('Exeunt', 'Scena', 'Quinta') 2\n",
      "('Scena', 'Quinta', 'Enter') 2\n",
      "('That', 'I', 'may') 2\n",
      "('comes', 'Night', 'Lady') 2\n",
      "('Is', 'thy', 'Master') 2\n",
      "('Exeunt', 'Scena', 'Sexta') 2\n",
      "('Hoboyes', 'Torches', 'Enter') 2\n",
      "('Scena', 'Prima', 'Enter') 3\n",
      "('Prima', 'Enter', 'Banquo') 2\n",
      "('yet', 'I', 'see') 2\n",
      "('I', 'see', 'thee') 4\n",
      "('see', 'thee', 'still') 2\n",
      "('Scena', 'Secunda', 'Enter') 3\n",
      "('Enter', 'Macbeth', 'Macb') 4\n",
      "('Macb', 'I', 'haue') 2\n",
      "('I', 'haue', 'done') 4\n",
      "('God', 'blesse', 'vs') 2\n",
      "('Enter', 'Lady', 'Lady') 2\n",
      "('Scena', 'Tertia', 'Enter') 2\n",
      "('Knock', 'Knock', 'Knock') 5\n",
      "('Knock', 'Knock', 'Whos') 2\n",
      "('I', 'haue', 'almost') 2\n",
      "('Ring', 'Alarum', 'Bell') 2\n",
      "('Macb', 'Had', 'I') 2\n",
      "('Old', 'man', 'Tis') 2\n",
      "('Lords', 'Attendants', 'Macb') 2\n",
      "('Ban', 'I', 'good') 2\n",
      "('I', 'good', 'Lord') 5\n",
      "('good', 'Lord', 'Macb') 4\n",
      "('Macb', 'We', 'haue') 2\n",
      "('I', 'pray', 'Let') 2\n",
      "('All', 'Double', 'double') 3\n",
      "('trouble', 'Fire', 'burne') 3\n",
      "('Fire', 'burne', 'Cauldron') 3\n",
      "('burne', 'Cauldron', 'bubble') 3\n",
      "('Cauldron', 'bubble', '2') 2\n",
      "('Double', 'double', 'toyle') 2\n",
      "('double', 'toyle', 'trouble') 2\n",
      "('toyle', 'trouble', 'Fire') 2\n",
      "('Appar', 'Macbeth', 'Macbeth') 2\n",
      "('Macbeth', 'Macbeth', 'Macbeth') 2\n",
      "('I', 'take', 'leaue') 2\n",
      "('wilt', 'thou', 'Father') 2\n",
      "('thou', 'Father', 'Son') 2\n",
      "('Wife', 'Euery', 'one') 2\n",
      "('And', 'must', 'hangd') 2\n",
      "('haue', 'done', 'harme') 2\n",
      "('Scaena', 'Tertia', 'Enter') 2\n",
      "('Macd', 'I', 'haue') 2\n",
      "('Seyward', 'ten', 'thousand') 2\n",
      "('I', 'haue', 'words') 2\n",
      "('I', 'haue', 'knowne') 2\n",
      "('To', 'bed', 'bed') 2\n",
      "('Drum', 'Colours', 'Enter') 2\n",
      "('Menteth', 'Cathnes', 'Angus') 2\n",
      "('Now', 'dos', 'feele') 2\n",
      "('Colours', 'Enter', 'Malcolme') 2\n",
      "('Enter', 'Malcolme', 'Seyward') 3\n",
      "('Malcolme', 'Seyward', 'Macduffe') 2\n",
      "('Enter', 'Macduffe', 'Macd') 2\n",
      "('Haile', 'King', 'Scotland') 2\n"
     ]
    }
   ],
   "source": [
    "# Count trigrams\n",
    "trigrams = ngrams(tokenized, 3)\n",
    "freq_trigrams = nltk.FreqDist(trigrams)\n",
    "freq_dist = nltk.FreqDist(freq_trigrams)\n",
    "for k,v in freq_dist.items():\n",
    "    if v >1 :\n",
    "        print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMDB_1</th>\n",
       "      <th>IMDB_2</th>\n",
       "      <th>IMDB_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alive</th>\n",
       "      <td>0.275692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artifacts</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bridge</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carl</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>civilization</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coma</th>\n",
       "      <td>0.275692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>communication</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>communities</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>construction</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deputy</th>\n",
       "      <td>0.275692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>envisioned</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facilitate</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forces</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gravely</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grimes</th>\n",
       "      <td>0.275692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <td>0.209671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>injured</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>join</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead</th>\n",
       "      <td>0.275692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learn</th>\n",
       "      <td>0.275692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restore</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rick</th>\n",
       "      <td>0.209671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>risky</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ruins</th>\n",
       "      <td>0.275692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sheriff</th>\n",
       "      <td>0.275692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stay</th>\n",
       "      <td>0.275692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survivors</th>\n",
       "      <td>0.275692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trade</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wakes</th>\n",
       "      <td>0.275692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>washington</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>0.275692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 IMDB_1    IMDB_2    IMDB_3\n",
       "alive          0.275692  0.000000  0.000000\n",
       "artifacts      0.000000  0.000000  0.286807\n",
       "bridge         0.000000  0.288675  0.000000\n",
       "build          0.000000  0.000000  0.286807\n",
       "carl           0.000000  0.000000  0.286807\n",
       "civilization   0.000000  0.000000  0.286807\n",
       "coma           0.275692  0.000000  0.000000\n",
       "communication  0.000000  0.288675  0.000000\n",
       "communities    0.000000  0.288675  0.000000\n",
       "construction   0.000000  0.288675  0.000000\n",
       "deputy         0.275692  0.000000  0.000000\n",
       "envisioned     0.000000  0.000000  0.286807\n",
       "facilitate     0.000000  0.288675  0.000000\n",
       "forces         0.000000  0.288675  0.000000\n",
       "gravely        0.000000  0.288675  0.000000\n",
       "grimes         0.275692  0.000000  0.000000\n",
       "group          0.209671  0.000000  0.218124\n",
       "injured        0.000000  0.288675  0.000000\n",
       "join           0.000000  0.288675  0.000000\n",
       "lead           0.275692  0.000000  0.000000\n",
       "learn          0.275692  0.000000  0.000000\n",
       "make           0.000000  0.000000  0.286807\n",
       "need           0.000000  0.000000  0.286807\n",
       "restore        0.000000  0.288675  0.000000\n",
       "rick           0.209671  0.000000  0.218124\n",
       "risky          0.000000  0.000000  0.286807\n",
       "ruins          0.275692  0.000000  0.000000\n",
       "run            0.000000  0.000000  0.286807\n",
       "search         0.000000  0.000000  0.286807\n",
       "sheriff        0.275692  0.000000  0.000000\n",
       "site           0.000000  0.288675  0.000000\n",
       "stay           0.275692  0.000000  0.000000\n",
       "survivors      0.275692  0.000000  0.000000\n",
       "trade          0.000000  0.288675  0.000000\n",
       "wakes          0.275692  0.000000  0.000000\n",
       "washington     0.000000  0.000000  0.286807\n",
       "world          0.275692  0.000000  0.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testat Aufgabe 2 - TF-IDF\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "imdb_text = [\n",
    "    \"Sheriff Deputy Rick Grimes wakes up from a coma to learn the world is in ruins, and must lead a group of survivors to stay alive.\",\n",
    "    \"The communities join forces to restore a bridge that will facilitate communication and trade; someone is gravely injured at the construction site.\",\n",
    "    \"Rick and his group make a risky run into Washington, D.C. to search for artifacts they will need to build the civilization he and Carl envisioned.\"\n",
    "]\n",
    "\n",
    "documents_names = [\"IMDB_1\", \"IMDB_2\", \"IMDB_3\"]\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,1))\n",
    "tfidf = vect.fit_transform(imdb_text).todense()\n",
    "pd.DataFrame(tfidf, columns=vect.get_feature_names(), index=documents_names).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
